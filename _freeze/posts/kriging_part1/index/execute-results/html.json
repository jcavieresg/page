{
  "hash": "55ec4da31a08cbe4719fba8b90ed4e2c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Understanding Kriging (Part 1)\"\nauthor: \"Joaquin Cavieres\"\ndate: \"2025-05-14\"\ncategories: [code, analysis]\nimage: \"image.jpg\"\n---\n\n\n\nIn this first blog post, I would like to share my thoughts on how the Kriging method can often lead to confusion due to its different interpretations. My goal is to help readers distinguish between Kriging as a \"**best linear unbiased predictor (BLUP)**\" for point-referenced spatial data, and its probabilistic interpretation as a **Gaussian random field** (the term \"Gaussian process\" I prefer using it for data without a spatial reference (I mean probabilistic because the following results are not based in the likelihood method, for now).\n\nIn Part 1, I will present the equations used to calculate the Kriging weights and demonstrate how to predict values at specific spatial locations. Using these weights, we will then perform interpolation over a regular square grid covering the entire spatial domain of interest. Finally, the results from our manual calculations will be compared with those obtained using the \"*`gstat`*\" package to assess their consistency and accuracy.\n\n\n\n::: {.cell}\n\n:::\n\n\n\n# Introduction\n\nWe will denote the spatial locations as $\\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_n\\}$, and the spatial data collected at these locations (the observed or measurement variable) will be denoted as $Z(\\mathbf{s}_1), \\ldots, Z(\\mathbf{s}_n)$. The spatial locations are determined by their coordinates in the space, for example, *latitude-longitude* and we will be mainly focused in the two-dimensional space. To denote the vector of all the observations we will use $\\mathbf{Z} = (Z(\\mathbf{s}_1), \\ldots, Z(\\mathbf{s}_n))^{\\top}$.\n\n# Computing the distance\n\nDistance is a numerical description of how far apart things are. It is the most fundamental concept in geography. Considering the Waldo Tobler's first law of the geography which says \\textcolor{blue}{`everything is related to everything else, but near things are more related than distant things'}, we need to quantify this relationship in some way and it is not always as easy a question as it seems.\n\nComputing the distance between a set of spatial data points is very important for spatial data analysis. If we have $\\mathbf{s}_i$ spatial locations, for $i = 1, \\ldots, n$, with $n$ equal to the total number of spatial locations. The coordinates of $\\mathbf{s}_i$ are in *latitude-longitude* but for simplicity, we will denote them as $(x_i,y_i)$. Now, another set of spatial locations $\\mathbf{s}_j$ has coordinates $(x_i, y_j)$, hence the Euclidean distance between spatial points $\\mathbf{s}_i$ and $\\mathbf{s}_j$ is given by\n\n$$\n\\begin{equation}\\text{dist\\_matrix}_{ij} = \\sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}.\\end{equation}\n$$ {#eq-1}\n\nThere are other forms to calculate the distance, for example; great-circle distance, azimuth distance, travel distance from point to point, time needed to get from point to point, etc.).\n\nThe computation of \"distances\" are commonly represented by the distance matrix. In this object (the distance matrix) we have all the values calculated for the distances between the objects of interest. For example,\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsite1 <- c(30, 45) \nsite2 <- c(95, 5)\nsite3 <- c(80, 45)\nsite4 <- c(90, 55)\nsite5 <- c(70, 30)\nsite6 <- c(30, 8)\nsites <- rbind(site1, site2, site3, site4, site5, site6)\nsites\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      [,1] [,2]\nsite1   30   45\nsite2   95    5\nsite3   80   45\nsite4   90   55\nsite5   70   30\nsite6   30    8\n```\n\n\n:::\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(sites, xlim=c(0,100), ylim=c(0,100), pch=20, cex=2, col='red', xlab='X', ylab='Y', las=1)\ntext(sites+3, c(\"site1\", \"site2\", \"site3\", \"site4\", \"site5\", \"site6\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' fig-pos='H' width=624}\n:::\n:::\n\n\n\nUsing these data, we can compute the distance between spatial points (distance matrix) as:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute Euclidean distances\ndist_matrix <- as.matrix(dist(sites))\ndist_matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         site1    site2    site3    site4    site5    site6\nsite1  0.00000 76.32169 50.00000 60.82763 42.72002 37.00000\nsite2 76.32169  0.00000 42.72002 50.24938 35.35534 65.06919\nsite3 50.00000 42.72002  0.00000 14.14214 18.02776 62.20129\nsite4 60.82763 50.24938 14.14214  0.00000 32.01562 76.21680\nsite5 42.72002 35.35534 18.02776 32.01562  0.00000 45.65085\nsite6 37.00000 65.06919 62.20129 76.21680 45.65085  0.00000\n```\n\n\n:::\n:::\n\n\n\n# (Semi)Variogram\n\nIn simple terms, it is a function of difference over distance. In mathematical terms, we could define it as the expected squared difference between values separated by a distance vector, generally denoted as $h$. The equation of the Variogram is the following\n\n$$\n\\begin{equation}\n\\gamma(\\mathbf{h}) = \\frac{1}{2}\\text{Var}[Z(\\mathbf{s}) - Z(\\mathbf{s} + \\mathbf{h})],\n\\end{equation}\n$$ {#eq-2}\n\nwhere $\\mathbf{s}$ is the spatial location, $\\mathbf{h}$ is the vector of distance between two spatial points, and $\\gamma(\\mathbf{h})$ measured how dissimilar the field values become as $\\mathbf{h}$ increases (this is for a third type of stationarity (**intrinsic stationarity**) and assuming that $\\mathbb{E}[Z(\\mathbf{s} + \\mathbf{h}) - Z(\\mathbf{s})] = 0$). The relationship of the variogram and the covariance function is given by:\n\n\n\n```{=tex}\n\\begin{align*}\n2\\gamma(\\mathbf{h}) \\hspace{2mm} = & \\text{Var}[Z(\\mathbf{s}) - Z(\\mathbf{s} + \\mathbf{h})] \\\\\n= & \\text{Var}(Z(\\mathbf{s} + \\mathbf{h}) + \\text{Var}(Z(\\mathbf{s}) - 2Cov(Z(\\mathbf{s} + \\mathbf{h}, Z(\\mathbf{s})\\\\\n= & C(0) + C(0) - 2C(\\mathbf{h})\n\\end{align*}\n```\n\n\nThus,\n\n$$\n\\gamma(\\mathbf{h}) = C(0) - C(\\mathbf{h}). \n$$ {#eq-3}\n\n## Empirical Variogram\n\nTraditionally, the selection of a variogram model begins with plotting the **empirical semivariogram** (Matheron (1963)). This empirical plot is then visually compared against various theoretical models to identify the most appropriate fit. The standard form of the empirical semivariogram is given by\n\n$$\n\\hat{\\gamma}(\\mathbf{h}) = \\frac{1}{2n(\\mathbf{h})} \\sum^{n(\\mathbf{h})}_{i,j}(Z(\\mathbf{s}_i) - Z(\\mathbf{s}_j))^{2}\n$$ {#eq-4}\n\nwhere $Z(\\mathbf{s}_i)$ and $Z(\\mathbf{s}_j)$ are the values (in the space) at the spatial locations $\\mathbf{s}$. Finally, we will denote the **variogram** as $2 \\gamma(\\mathbf{h})$.\n\n<!-- We can write the variance (stationary) of $Z(\\mathbf{s})$ and $Z(\\mathbf{s} + \\mathbf{h})$ as $\\sigma^{2}_{\\mathbf{s}} = \\mathbb{E}[Z^2] - \\mu^2$ (for some mean $\\mu$). Thus, the spatial covariance between $Z(\\mathbf{s})$ and $Z(\\mathbf{s} + \\mathbf{h})$ can be written as -->\n\n<!-- $$ -->\n\n<!-- \\begin{equation}C(\\mathbf{h}) = \\mathbb{E}[Z(\\mathbf{s}) - \\mu] [Z(\\mathbf{s} + \\mathbf{h}) - \\mu] = \\mathbb{E}[Z(\\mathbf{s}) Z(\\mathbf{s} + \\mathbf{h})] - \\mu^2\\end{equation} -->\n\n<!-- $$ -->\n\n<!-- If we assume that the $\\mu$ is stationary, then -->\n\n<!-- $$ -->\n\n<!-- \\begin{align*}2\\gamma(\\mathbf{h}) = & \\mathbb{E}[Z(\\mathbf{s})^2] - \\mu^2 - 2\\mathbb{E}[Z(\\mathbf{s}) Z(\\mathbf{s} + \\mathbf{h})] + 2\\mu^2 + \\mathbb{E}[Z(\\mathbf{s} + \\mathbf{h})] - \\mu^2 \\\\\\gamma(\\mathbf{h}) = & \\sigma^{2}_{\\mathbf{s}} - C(\\mathbf{h}) \\hspace{4mm} \\text{or} \\rightarrow  C(\\mathbf{h}) = \\sigma^{2}_{\\mathbf{s}} - \\gamma(\\mathbf{h})\\end{align*} -->\n\n<!-- $$ -->\n\n<!-- [These relations are valid for a spatial variables with a stationary mean and variance.]{style=\"color:blue;\"} <!--#  -->\n\nThe typical variogram models are:\n\n-   [Exponential]{.underline}:\n\n    $\\gamma(\\mathbf{h}) = \\sigma^2 \\left(1 - \\exp\\left(-\\frac{\\mathbf{h}}{\\rho}\\right)\\right)$\n\n-   [Spherical:]{.underline}\n\n\n\n    ```{=tex}\n    \\begin{equation*}\n    \\gamma(\\mathbf{h}) =\n    \\begin{cases}\n    \\sigma^2 \\left[\\frac{3\\mathbf{h}}{2\\rho} - \\frac{\\mathbf{h}^3}{2\\rho^3}\\right], & \\text{if } 0 \\le \\mathbf{h} \\le \\rho \\\\\\sigma^2, & \\text{if } \\mathbf{h} > \\rho\n    \\end{cases}\n    \\end{equation*}\n    ```\n\n\n\n-   [Gaussian:]{.underline}\n\n    $\\gamma(\\mathbf{h}) = \\sigma^2 \\left(1 - \\exp\\left(-\\left(\\frac{\\mathbf{h}}{\\rho}\\right)^2\\right)\\right)$\n\nFor all the variograms presented, $\\rho$ is the range parameter.\n\n# Variogram computation\n\nFrom the @eq-4, we know that; $n(\\mathbf{h})$ is the number of spatial points for a specific distance vector $\\mathbf{h}$, with $Z(\\mathbf{s})$ and $Z(\\mathbf{s} + \\mathbf{h})$ and $2 \\gamma(\\mathbf{h})$ is the variogram.\n\nFirst, we will consider the following important observations before of the computation:\n\n1.  [As the distance increase, then the variability also increase]{.underline}: this is typical, as larger distance offsets generally lead to greater differences between the head and tail samples.\n2.  [It is calculated over all possible pairs separated by the distance vector $\\mathbf{h}$]{.underline}: we evaluate all data, identifying all possible pair combinations with every other spatial point. The variogram is then calculated as half the expected squared difference between these pairs. A larger number of pairs provides a more reliable estimate\n3.  [It is necessary plot the **sill** to know the correlation between the spatial points:]{.underline} here, sill is the spatial variance $\\sigma^2_{\\mathbf{s}}$. As we are assuming stationarity, the covariance is:\n\n\n\n```{=tex}\n\\begin{equation*}\nC(\\mathbf{h}) = \\sigma^2_\\mathbf{s} - \\gamma(\\mathbf{h})\n\\end{equation*}\n```\n\n\nThe covariance measure the similarity over distance, and if $\\sigma^2_{\\mathbf{s}} = 1.0$, $C(\\mathbf{h})$ is equal to the correlogram $\\rho(\\mathbf{h})$ such that\n\n\n\n```{=tex}\n\\begin{equation}\n\\rho(\\mathbf{h}) = \\sigma^2_\\mathbf{s} - \\gamma(\\mathbf{h})\n\\end{equation}\n```\n\n\n4)  [The distance at which the variogram reaches $\\sigma^2_{\\mathbf{s}}$ is known as the **range**]{.underline}: the distance in which the difference of the variogram from $\\sigma^2_{\\mathbf{s}}$ becomes negligible.\n\n5)  [Evaluate the discontinuity at the origin, the **nugget effec**t]{.underline}: It represents variability in the data that occurs at scales smaller than the sampling distance, or it may be caused by measurement errors or random noise.\n\n## Practical example\n\n<!-- Let consider a set of spatial data points (location) with known coordinates $\\mathbf{s}_1, \\mathbf{s}_2, \\dots, \\mathbf{s}_n$ and observed values $Z(\\mathbf{s}_1), Z(\\mathbf{s}_2), \\dots, Z(\\mathbf{s}_n)$. -->\n\n<!-- 1.  Define the empirical variogram estimator $\\hat{\\gamma}(\\mathbf{h})$. -->\n\nGiven the following observations:\n\n\n\n```{=tex}\n\\begin{equation*}\nZ(\\mathbf{s}_1) = 10, \\hspace{2mm} Z(\\mathbf{s}_2) = 12, \\hspace{2mm} Z(\\mathbf{s}_3) = 14, \\hspace{2mm} Z(\\mathbf{s}_4) = 13, \\hspace{2mm} Z(\\mathbf{s}_5) = 15 \n\\end{equation*}\n```\n\n\nand the corresponding distances between the points (the distance matrix)\n\n\n\n```{=tex}\n\\begin{bmatrix}\n0 & 2 & 4 & 6 & 8 \\\\\n2 & 0 & 2 & 4 & 6 \\\\\n4 & 2 & 0 & 2 & 4 \\\\\n6 & 4 & 2 & 0 & 2 \\\\\n8 & 6 & 4 & 2 & 0\n\\end{bmatrix}\n```\n\n\nCalculate the experimental variogram for the distance $\\mathbf{h} = 2$.\n\n**Solution**: The empirical variogram estimator $\\hat{\\gamma}(\\mathbf{h})$ for $\\mathbf{h}$ is defined as:\n\n\n\n```{=tex}\n\\begin{equation*}\n\\hat{\\gamma}(\\mathbf{h}) = \\frac{1}{2 n(\\mathbf{h})} \\sum^{n(\\mathbf{h})}_{i,j} \\left( Z(\\mathbf{s}_i) - Z(\\mathbf{s}_j) \\right)^2,\n\\end{equation*}\n```\n\n\nwhere $n(\\mathbf{h})$ is the number of pairs $(i, j)$ such that the distance between $\\mathbf{s}_i$ and $\\mathbf{s}_j$ is approximately $\\mathbf{h}$.\n\n1.  For $\\mathbf{h} = 2$, the pairs of points whose distance is 2 are:\n\n    -   $(\\mathbf{s}_1, \\mathbf{s}_2)$\n    -   $(\\mathbf{s}_2, \\mathbf{s}_3)$\n    -   $(\\mathbf{s}_3, \\mathbf{s}_4)$\n    -   $(\\mathbf{s}_4, \\mathbf{s}_5)$\n\n    We now calculate the squared differences for each pair of spatial points:\n\n\n\n    ```{=tex}\n    \\begin{aligned}\n    \\left( Z(\\mathbf{s}_1) - Z(\\mathbf{s}_2) \\right)^2 &= (10 - 12)^2 = 4, \\\\\n    \\left( Z(\\mathbf{s}_2) - Z(\\mathbf{s}_3) \\right)^2 &= (12 - 14)^2 = 4, \\\\\n    \\left( Z(\\mathbf{s}_3) - Z(\\mathbf{s}_4) \\right)^2 &= (14 - 13)^2 = 1, \\\\\n    \\left( Z(\\mathbf{s}_4) - Z(\\mathbf{s}_5) \\right)^2 &= (13 - 15)^2 = 4.\n    \\end{aligned}\n    ```\n\n\n    Now, compute the empirical variogram:\n\n\n\n    ```{=tex}\n    \\begin{equation*}\n    \\hat{\\gamma}(2) = \\frac{1}{2 \\times 4} \\left( 4 + 4 + 1 + 4 \\right) = \\frac{1}{8} \\times 13 = 1.625.\n    \\end{equation*}\n    ```\n\n\n    Thus, for $\\mathbf{h} = 2$ is $\\hat{\\gamma}(2) = 1.625$.\n\n## Using the \"*`gstat`*\" package of R\n\nThe \"*`gstat`*\" package in R is a versatile tool used for geostatistical modelling, spatial prediction, and multivariable geostatistics [@pebesma2004multivariable]. It provides functionality for variogram modeling, Kriging, and conditional simulation, supporting univariate and multivariate spatial data. Some of the main features of this library are the following:\n\n-   **Computing the variogram** $\\rightarrow$ empirical variogram (also called experimental) and variogram fitting (variogram modeling).\n\n-   **Kriging** $\\rightarrow$ ordinary, simple, and universal kriging.\n\n-   **Multivariable geostatistics** $\\rightarrow$ co-kriging and other methods for spatial modelling.\n\n-   **Simulation** $\\rightarrow$ conditional and unconditional GRF for spatial predictions.\n\nThe \"*`gstat`*\" package is simple to use and here are the basics steps for spatial data analysis\n\n1.  Define spatial data ( a $\\texttt{SpatialPointsDataFrame})$ from the \"*`sp`*\" package.\n2.  Compute the empirical variogram using the function $\\texttt{variogram()}$\n3.  Fit a variogram model using the function $\\texttt{fit.variogram()}$\n4.  Perform kriging prediction with the $\\texttt{krige()}$ function.\n\nFor the California air pollution data (from the \"*`rspatial`*\" package), select the \"airqual\" data and interpolate the levels of ozone (averages for 1980-2009). Here, you must consider \"OZDLYAV\" (unit is parts per billion) for interpolation purposes.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Installing the rspat package\nif (!require(\"rspatial\")) remotes::install_github('rspatial/rspatial')\n\n# Read the data\nlibrary(rspatial)\nx <- sp_data(\"airqual\")\nx$res <- x$OZDLYAV * 1000\n```\n:::\n\n\n\nNow, we create a $\\texttt{SpatialPointsDataFrame}$ and transform to Teale Albers. Note the units=km, which was needed to fit the variogram.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#===================================\n#         Installing rgdal\n#===================================\n# url <- \"https://download.r-forge.r-project.org/bin/windows/contrib/4.4/rgdal_1.6-7.zip\"\n# install.packages(url, type=\"source\", repos=NULL)\n\nlibrary(rgdal)\ncoordinates(x) <- ~LONGITUDE + LATITUDE\nproj4string(x) <- CRS('+proj=longlat +datum=NAD83')\nTA <- CRS(\"+proj=aea +lat_1=34 +lat_2=40.5 +lat_0=0 +lon_0=-120 +\n          x_0=0 +y_0=-4000000 +datum=WGS84 +units=km\")\ncoords <- spTransform(x, TA)\n```\n:::\n\n\n\nNow we will create an empirical variogram using the package \"*`gstat`*\" as follow\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(gstat)\ngs <- gstat(formula = res~1, locations = coords)\nv <- variogram(gs, width=20)\nhead(v)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    np      dist    gamma dir.hor dir.ver   id\n1 1010  11.35040 34.80579       0       0 var1\n2 1806  30.63737 47.52591       0       0 var1\n3 2355  50.58656 67.26548       0       0 var1\n4 2619  70.10411 80.92707       0       0 var1\n5 2967  90.13917 88.93653       0       0 var1\n6 3437 110.42302 84.13589       0       0 var1\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(v)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' fig-pos='H' width=576}\n:::\n:::\n\n\n\nand then fit a model variogram\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfve <- fit.variogram(v, vgm(85, \"Exp\", 75, 20))\nfve\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  model    psill    range\n1   Nug 21.96600  0.00000\n2   Exp 85.52957 72.31404\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(variogramLine(fve, 400), type='l', ylim=c(0,120))\npoints(v[,2:3], pch=20, col='red')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' fig-pos='H' width=576}\n:::\n:::\n\n\n\nYou can change the type of variograms (spherical in stead of exponential) and compare them\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfvs <- fit.variogram(v, vgm(85, \"Sph\", 75, 20))\nfvs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  model    psill    range\n1   Nug 25.57019   0.0000\n2   Sph 72.65881 135.7744\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(variogramLine(fvs, 400), type='l', ylim=c(0,120) ,col='blue', lwd=2)\npoints(v[,2:3], pch=20, col='red')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' fig-pos='H' width=576}\n:::\n:::\n\n\n\n# Kriging\n\nThis section introduces the traditional method for spatial prediction in point-referenced data, which aims to minimize the mean squared prediction error. Known as **Kriging**, this technique was formalized by [@matheron1963], who named it in tribute to Danie G. Krige [@krige1951]. Here, the main task is finding an optimal spatial prediction, that is; giving a vector of observations $\\mathbf{Z} = (Z(\\mathbf{s}_1), \\ldots, Z(\\mathbf{s}_n))^{\\top}$ the goal is accurately estimate values at an unsampled location $Z(\\mathbf{s}_0)$. So, basically the question is; what is the best predictor of the value of $Z(\\mathbf{s}_0)$ based upon the data $\\mathbf{Z}$?\n\n## Ordinary Kriging\n\nLet consider the observed values $\\mathbf{Z} = (Z(\\mathbf{s}_1), Z(\\mathbf{s}_2), \\dots, Z(\\mathbf{s}_n))^{\\top}$ at known locations $\\{\\mathbf{s}_1, \\mathbf{s}_2, \\dots, \\mathbf{s}_n\\}$. The goal is to predict the value of a random field $Z(\\mathbf{s}_0)$ at an unobserved location $\\mathbf{s}_0$. The model assumption for this case is the following:\n\n$$\n\\mathbf{Z} = \\mu  + \\delta(\\mathbf{s}), \\hspace{6mm} \\mathbf{s} \\in S, \\hspace{2mm} \\mu \\in \\mathbb{R} (\\text{unknown})\n$$\n\nwhere $\\delta(\\mathbf{s})$ is a zero-mean spatial stochastic process with variogram or with some covariance function and $S \\subset \\mathbb{R}^{d}$, with $d$ being a dimensional Euclidean space. For this case, Kriging assumes a spatial random field expressed through a variogram or covariance function, and allows to face this spatial rediction problem. In this case, the Ordinary Kriging predictor for $Z(\\mathbf{s}_0)$ is a **linear combination of the observed values** such that:\n\n\n\n```{=tex}\n\\begin{equation*}\n\\hat{Z}(\\mathbf{s}_0) = \\sum_{i=1}^n w_i Z(\\mathbf{s}_i),\n\\end{equation*},\n```\n\n\nwhere $w_i$, for $i = 1, \\ldots, n$ are the Kriging weights that need to be calculated. In this way, Kriging minimizes the mean squared error of the prediction such that:\n\n\n\n```{=tex}\n\\begin{equation*}\n\\text{min} \\hspace{2mm}\\sigma^{2}_{\\text{error}} = \\mathbb{E}[Z(\\mathbf{s}_0) - \\hat{Z}(\\mathbf{s}_0)]^{2}\n\\end{equation*},\n```\n\n\nor\n\n$$\n\\text{min}\\hspace{2mm} \\sigma^{2}_{\\text{error}} = \\mathbb{E}[Z(\\mathbf{s}_0) - \\sum_{i=1}^n w_i Z(\\mathbf{s}_i)]^{2} \n$$ {#eq-5}\n\nIn terms of a **covariance function**, for a zero-mean and second order stationary spatial process, and also considering to $C(\\mathbf{h}), \\mathbf{h} \\in \\mathbb{R}^{d}$, then @eq-5 can be written as:\n\n\n\n```{=tex}\n\\begin{equation}\n\\sigma^{2}_{\\text{error}} = C(0) - 2 \\sum^{n}_{i=1}w_iC(\\mathbf{s}_0, \\mathbf{s}_i) + \\sum^{n}_{i=1}\\sum^{n}_{j=1} w_{i}w_{j}C(\\mathbf{s}_i, \\mathbf{s}_j).\n\\end{equation}\n```\n\n\nThe ordinary Kriging weights $w_i$ must satisfy two requirements:\n\n-   **Unbiasedness**: The predictor should be unbiased, which requires that $\\sum_{i=1}^n w_i = 1$.\n\n-   **Optimality**: The weights should minimize the variance of the prediction error (the Kriging variance), leading to the solution of a system of equations.\n\nThe unbiasedness requirement ensures that the expected value of the Kriging predictor matches the expected value of the random field, preventing systematic over- or under-prediction (interpolation).\n\n## Finding the Kriging weights\n\nBased on the data $\\mathbf{Z}$ and $\\{\\mathbf{s}_1, \\ldots, \\mathbf{s}_n\\}$, with $C(\\mathbf{h})$ being a covariance function of the spatial random field, and $\\mathbf{h} = \\mathbf{s}_i - \\mathbf{s}_j$, for **Ordinary Kriging** we can write a **linear system of equations** fo find the Kriging weights $w_1, \\ldots, w_n$. But, how can we propose this system of equations? Well, we already know that the ordinary Kriging estimator is a linear combination of the observed values,\n\n\n\n```{=tex}\n\\begin{equation*}\n\\hat{Z}(\\mathbf{s}_0) = \\sum^{n}_{i=1} w_i Z(\\mathbf{s}_i),\n\\end{equation*}\n```\n\n\nand since that here we are considering the covariance then the minimization problem can be written as:\n\n$$\n\\text{min} \\hspace{2mm} C(0) - 2\\sum^{n}_{i=1}w_{i}C(\\mathbf{s}_0, \\mathbf{s}_i) + \\sum^{n}_{i=1}\\sum^{n}_{j=1}w_{i}w_{j}C(\\mathbf{s}_i, \\mathbf{s}_j) + 2\\mathcal{M}(\\sum^{n}_{i=1} w_i - 1)\n$$ {#eq-6}\n\nwhere $\\mathcal{M}$ is the Lagrange multiplier. Thus, after differentiating @eq-6 with respect $w_{1}, \\ldots, w_{n}$ and $\\mathcal{M}$, and set the derivatives equal to zero we have:\n\n\n\n```{=tex}\n\\begin{align*}\n2\\sum^{n}_{j=1}w_{j}C(\\mathbf{s}_i, \\mathbf{s}_j) - 2C(\\mathbf{s}_0, \\mathbf{s}_i) - 2\\mathcal{M} \\hspace{2mm} = & 0 \\\\\n\\sum^{n}_{j=1}w_{j} C(\\mathbf{s}_i - \\mathbf{s}_j) + C(\\mathbf{s}_0 - \\mathbf{s}_i) - \\mathcal{M} \\hspace{2mm} = & \\hspace{2mm} 0 \\\\\n\\sum^{n}_{i=1}w_{i} \\hspace{2mm} = & \\hspace{2mm} 1\n\\end{align*}\n```\n\n\nTherefore, using a matrix notation to find $w_{1}, \\ldots, w_{n}$ we propose the following linear system of equations:\n\n$$\n\\boldsymbol{\\Gamma}\\mathbf{w} = \\mathbf{c},\n$$\n\nwhere:\n\n-   $\\mathbf{w} = (w_{1}, \\ldots, w_{n}, -\\mathcal{M})^{\\top}$.\n\n-   $\\mathbf{c} = (C(\\mathbf{s}_0, \\mathbf{s}_1), \\ldots, C(\\mathbf{s}_0, \\mathbf{s}_n), 1)^{\\top}$.\n\n-   $\\boldsymbol{\\Gamma} = C(\\mathbf{s}_i, \\mathbf{s}_j), \\hspace{2mm} i = 1, \\ldots, n, \\hspace{2mm} j = 1, \\ldots, n$.\n\nThus, expressed in a linear system of equations (the **Kriging system):**\n\n\n\n```{=tex}\n\\begin{equation*}\n\\begin{pmatrix}\nC(\\mathbf{s}_1, \\mathbf{s}_1) & C(\\mathbf{s}_1, \\mathbf{s}_2) & \\dots & C(\\mathbf{s}_1, \\mathbf{s}_n) & 1 \\\\\nC(\\mathbf{s}_2, \\mathbf{s}_1) & C(\\mathbf{s}_2, \\mathbf{s}_2) & \\dots & C(\\mathbf{s}_2, \\mathbf{s}_n) & 1 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\nC(\\mathbf{s}_n, \\mathbf{s}_1) & C(\\mathbf{s}_n, \\mathbf{s}_2) & \\dots & C(\\mathbf{s}_n, \\mathbf{s}_n) & 1 \\\\\n1 & 1 & \\dots & 1 & 0 \\\\\n\\end{pmatrix}\n\\begin{pmatrix}\nw_1 \\\\\nw_2 \\\\\n\\vdots \\\\\nw_n \\\\\n-\\mathcal{M} \\\\\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nC(\\mathbf{s}_1, \\mathbf{s}_0) \\\\\nC(\\mathbf{s}_2, \\mathbf{s}_0) \\\\\n\\vdots \\\\\nC(\\mathbf{s}_n, \\mathbf{s}_0) \\\\\n1 \\\\\n\\end{pmatrix}\n\\end{equation*}\n```\n\n\nWe can find $\\hat{\\mathbf{w}}$ as\n\n$$\n\\hat{\\mathbf{w}} = \\boldsymbol{\\Gamma}^{-1}\\mathbf{c}.\n$$\n\nFinally, the Kriging variance, which quantifies the uncertainty of the prediction at $\\mathbf{s}_0$, is given by:\n\n\n\n```{=tex}\n\\begin{equation*}\n\\sigma_\\text{OK}^2(\\mathbf{s}_0) = C(\\mathbf{0}) - \\sum_{i=1}^n w_i C(\\mathbf{s}_i - \\mathbf{s}_0) - \\mathcal{M}\n\\end{equation*},\n```\n\n\nwhere lower Kriging variance indicates a reliable prediction (interpolation) values.\n\n# Example using R\n\nWe will simulate some spatial data (point referenced or geostatistical data) to compute manually the Ordinary Kriging predictor using the Kriging system.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load neccesary libraries\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(magrittr)\n\n\n# Simulating the spatial locations\nset.seed(123)\nn <- 100\nlocations <- matrix(runif(2 * n, 1, 10), ncol = 2)\n# Simulating the observed values at these locations\nz_values <- rnorm(n, mean = 10, sd = 2)\n```\n:::\n\n\n\nThe next step is to choose an appropriate covariance function for modeling spatial dependence. While several types of covariance (or correlation) functions are available for spatial data, we will use the **Exponential covariance function** for its simplicity and effectiveness. It is defined as:\n\n\n\n```{=tex}\n\\begin{equation*} \nC(\\mathbf{h}) = \\sigma^{2}\\exp\\bigg (\\frac{\\mathbf{h}}{\\rho} \\bigg ),\n\\end{equation*}\n```\n\n\nwhere $\\sigma^{2}$ is the sill (representing the **variance of the spatial process at zero distance**), $\\rho$ is the range (controls how **quickly the correlation decays** with distance) and $\\mathbf{h}$ is the distance between two locations. We will create this function in R:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Exponential covariance function\nexp_cov <- function(h, sill = 1, range = 3) {\n  sill * exp(-h / range)}\n```\n:::\n\n\n\nNow we will build the covariance matrix\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Build the covariance matrix\ncov_mat <- matrix(0, nrow = n + 1, ncol = n + 1)\nnugget <- 1e-10\n\nfor (i in 1:n) {\n  for (j in 1:n) {\n    h <- sqrt(sum((locations[i, ] - locations[j, ])^2))\n    cov_mat[i, j] <- exp_cov(h)\n  }\n  cov_mat[i, n + 1] <- 1  # Add 1s for constraint\n  cov_mat[n + 1, i] <- 1\n}\ncov_mat[n + 1, n + 1] <- 0  # Lagrange multiplier part\ndiag(cov_mat)[1:n] <- diag(cov_mat)[1:n] + nugget\n```\n:::\n\n\n\nAt this point, we have all the elements to predict manually a specific value in a spatial coordinate $\\mathbf{s_0} = (s_1, s_2)^{T}$. For example, if we are interested in the prediction in the spatial coordinates *longitude* = 5, and *latitude* = 5. This means, $\\mathbf{s_0} = (latitude, longitude) = (5, 5)$, hence we want to predict $\\hat{Z}(\\mathbf{s}_0)$. Now, applying the exponential covariance function to the right side of the linear system:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Cov between new coordinates and known points\n# Location for prediction\ns0 <- c(5, 5)\n\n# Initializing the cov in the right hand side\nc_rhs <- numeric(n + 1)\nfor (i in 1:n) {\n  h <- sqrt(sum((locations[i, ] - s0)^2))\n  c_rhs[i] <- exp_cov(h)\n}\nc_rhs[n + 1] <- 1  # constraint\n```\n:::\n\n\n\nFinally, we will solve the Kriging system\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fiding w and Lagrange multiplier (M)\nsol <- solve(cov_mat, c_rhs)\nw <- sol[1:n]; w\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1]  5.276449e-04 -1.803309e-04  1.808293e-02  3.633872e-05  3.512794e-07\n  [6]  4.037552e-06 -1.075393e-04 -4.808129e-05  1.185162e-01 -2.727913e-04\n [11]  7.221219e-05  2.943618e-02 -8.813330e-05 -1.101876e-05 -2.536848e-05\n [16] -5.618937e-06 -2.864650e-03  7.090709e-05 -1.194771e-02  3.334460e-05\n [21] -1.292535e-05 -4.060164e-04 -4.474131e-04  3.765660e-05 -6.044917e-03\n [26]  4.564017e-05 -4.555052e-04 -8.970886e-05 -6.535305e-05  7.507714e-05\n [31]  6.314879e-05  9.338884e-07 -4.830208e-04 -1.474871e-05  3.282166e-05\n [36] -5.492154e-03 -4.961159e-05  1.600371e-04  1.783362e-05 -2.947635e-03\n [41] -5.033814e-05  4.059160e-01 -3.603510e-05 -2.640918e-04 -3.769253e-05\n [46]  2.305515e-05 -1.535201e-05 -6.635154e-05 -1.800664e-03  1.070637e-05\n [51] -1.374114e-06  4.253124e-02  5.859619e-05  1.412490e-05 -8.819846e-05\n [56]  2.088056e-04  8.108485e-05 -2.172081e-04 -1.140082e-04 -2.971160e-03\n [61] -3.386579e-03  6.540672e-05 -5.333364e-03 -6.878677e-03  3.795126e-05\n [66] -1.479047e-02  6.800025e-06 -2.405783e-05 -2.911957e-04 -6.566962e-03\n [71] -5.174284e-04 -4.830647e-04 -1.256172e-04  2.572667e-05 -5.796527e-04\n [76]  5.918588e-04 -2.105901e-02  1.104930e-02  7.288147e-05  4.985706e-07\n [81]  4.945123e-05 -7.647327e-05  2.493547e-04 -6.589906e-05 -5.331597e-06\n [86]  4.589720e-01  5.533826e-06 -1.741735e-04 -8.916278e-06 -1.164895e-05\n [91] -2.342534e-05 -8.579970e-04  2.773732e-05 -2.368735e-03 -2.154586e-05\n [96] -1.211798e-04 -8.375836e-04 -1.596751e-05 -5.827816e-04  1.571912e-02\n```\n\n\n:::\n\n```{.r .cell-code}\nM <- sol[n + 1]; M\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.0002080739\n```\n\n\n:::\n:::\n\n\n\nWith these values, we will compute $\\hat{Z}(\\mathbf{s}_0)$ and the Kriging variance $\\sigma^{2}_{\\text{OK}}(\\mathbf{s}_0)$ as follows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Kriging estimate\nz_hat <- sum(w * z_values); z_hat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.516983\n```\n\n\n:::\n\n```{.r .cell-code}\n# Kriging variance\nc0 <- exp_cov(0)  # C(0)\nsigma_OK2 <- c0 - sum(w * c_rhs[1:n]) - M; sigma_OK2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1262456\n```\n\n\n:::\n:::\n\n\n\nAs we see, $\\hat{Z}(\\mathbf{s}_0) = 9.516983$ and $\\sigma^{2}_{\\text{OK}}(\\mathbf{s}_0) = 0.1262456$. This mean that the value in the location *longitude* = 5 and *latitude* = 5 is **9.516983** and the variance associated with this prediction is **0.1262456**. We will compare this result with the package \"*`gstat`*\":\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Using gstat\nspat_data <- data.frame(z_values, locations)\ncolnames(spat_data) <- c(\"z_values\", \"s1\", \"s2\")\n\n\n# Convert to spatial object\ncoordinates(spat_data) <- ~s1 + s2\n\n# Empirical variogram\nemp_vario <- variogram(z_values ~ 1, spat_data)\n\n# Fit a model variogram\nfit_vario <- fit.variogram(emp_vario, model = vgm(psill = 1, model = \"Exp\", range = 1, nugget = 0.1))\n\n\n# Create a data frame with the prediction location\ns0 <- data.frame(s1 = 5, s2 = 5)\n\n# Convert to spatial object\ncoordinates(s0) <- ~s1 + s2\n# Kriging\ns0_pred <- krige(z_values ~ 1, spat_data, s0, model = fit_vario)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[using ordinary kriging]\n```\n\n\n:::\n\n```{.r .cell-code}\nz_hat_gstat <- s0_pred$var1.pred; z_hat_gstat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 9.715304\n```\n\n\n:::\n\n```{.r .cell-code}\nz_var_gstat <- s0_pred$var1.var; z_var_gstat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.880513\n```\n\n\n:::\n:::\n\n\n\nComparing the prediction in location $\\mathbf{s}_0$, for Kriging computed manually and using \"*`gstat`*\" package, the values are very close (9.516983 and 9.715304, respectively). The variance for the prediction using \"*`gstat`*\" is 3.880513.\n\nFinally, we can compare the interpolation in a grid for both methods.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n#============================================\n#              Interpolation\n#============================================\n# Set up prediction grid\nbbox_vals <- bbox(spat_data)\n\n# Extract ranges\ngrid_size <- 100\ns1_seq <- seq(bbox_vals[1, 1] - 0.5, bbox_vals[1, 2] + 0.5, length.out = grid_size)\ns2_seq <- seq(bbox_vals[2, 1] - 0.5, bbox_vals[2, 2] + 0.5, length.out = grid_size)\n\n# Create prediction grid\ngrid_points <- expand.grid(x = s1_seq, y = s2_seq)\n\n\n# Initialize vector for predictions (interpolation)\nz_inter <- numeric(nrow(grid_points))\nvar_inter <- numeric(nrow(grid_points))\n\n# Loop over grid points\nfor (k in 1:nrow(grid_points)) {\n  s0 <- as.numeric(grid_points[k, ])\n  \n  # Build RHS covariance vector\n  c_rhs <- numeric(n + 1)\n  for (i in 1:n) {\n    h <- sqrt(sum((locations[i, ] - s0)^2))\n    c_rhs[i] <- exp_cov(h)\n  }\n  c_rhs[n + 1] <- 1\n  \n  # Solve for weights\n  sol <- solve(cov_mat, c_rhs)\n  w <- sol[1:n]\n  \n  # Kriging estimate\n  z_inter[k] <- sum(w * z_values)\n  var_inter[k] <- exp_cov(0) - sum(w * c_rhs[1:n]) + M\n}\n\n# Reshape result into matrix for plotting\nz_pred <- matrix(z_inter, nrow = grid_size, ncol = grid_size, byrow = FALSE)\nz_var  <- matrix(var_inter, nrow = grid_size, ncol = grid_size, byrow = FALSE)\n\n\n\n#====================================\n#     Using the \"gstat\" package\n#====================================\n# Convert grid to SpatialPoints\ncoordinates(grid_points) <- ~x + y\ngridded(grid_points) <- TRUE\n\n\n# Create gstat object for Kriging\nkrige_gstat <- krige(z_values ~ 1, spat_data, grid_points, model = fit_vario)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[using ordinary kriging]\n```\n\n\n:::\n\n```{.r .cell-code}\nz_pred_df <- expand.grid(x = s1_seq, y = s2_seq)\n\n# Adding a column of z values\nz_pred_df$z_values <- z_values\n\n# Predictions\nz_pred_df$z_pred <- as.vector(z_pred) \nz_pred_df$z_pred_gstat <- as.vector(krige_gstat$var1.pred)\n# Variances\nz_pred_df$z_var <- as.vector(z_var)\nz_pred_df$z_var_gstat <- as.vector(krige_gstat$var1.var)\n\n\n\n\n# Plot prediction + observed points\nspat_data <- data.frame(spat_data)\nhead(spat_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   z_values       s1       s2 optional\n1  8.579187 3.588198 6.399901     TRUE\n2 10.513767 8.094746 3.995412     TRUE\n3  9.506616 4.680792 5.397517     TRUE\n4  9.304915 8.947157 9.590264     TRUE\n5  8.096763 9.464206 5.346122     TRUE\n6  9.909945 1.410008 9.013152     TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\np1 <- ggplot(z_pred_df, aes(x = x, y = y)) +\n  geom_tile(aes(fill = z_pred)) +  # prediction surface\n  geom_point(data = spat_data, aes(x = s1, y = s2, size = z_values), color = \"blue\", alpha = 0.75) +\n  coord_equal() +\n  xlab(\"s1\") + ylab(\"s2\") + \n  scale_fill_gradient(low = \"yellow\", high = \"red\") +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = comma) +\n  theme_bw() +\n  labs(fill = \"Predicted z values (manually)\", size = \"Observed z values\") + \n  theme(axis.text=element_text(size=12),\n        axis.title=element_text(size=14,face=\"bold\"))\n\n\np2 <- ggplot(z_pred_df, aes(x = x, y = y)) +\n  geom_tile(aes(fill = z_pred_gstat)) +  # prediction surface\n  geom_point(data = spat_data, aes(x = s1, y = s2, size = z_values), color = \"blue\", alpha = 0.75) +\n  coord_equal() +\n  xlab(\"s1\") + ylab(\"s2\") + \n  scale_fill_gradient(low = \"yellow\", high = \"red\") +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = comma) +\n  theme_bw() +\n  labs(fill = \"Predicted z values (gstat)\", size = \"Observed z values\") +\n  theme(axis.text=element_text(size=12),\n        axis.title=element_text(size=14,face=\"bold\"))\n\n\ngrid.arrange(p1, p2, ncol = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){fig-align='center' width=960}\n:::\n\n```{.r .cell-code}\n# Variances\np3 <- ggplot(z_pred_df, aes(x = x, y = y)) +\n  geom_tile(aes(fill = z_var)) +  \n  geom_point(data = spat_data, aes(x = s1, y = s2, size = z_values), color = \"blue\", alpha = 0.75) +\n  coord_equal() +\n  xlab(\"s1\") + ylab(\"s2\") + \n  scale_fill_gradient(low = \"yellow\", high = \"red\") +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = comma) +\n  theme_bw() +\n  labs(fill = \"Variance of predictions (manually)\", size = \"Observed z\") +\n  theme(axis.text=element_text(size=12),\n        axis.title=element_text(size=14,face=\"bold\"))\n\n\np4 <- ggplot(z_pred_df, aes(x = x, y = y)) +\n  geom_tile(aes(fill = z_var_gstat)) +  \n  geom_point(data = spat_data, aes(x = s1, y = s2, size = z_values), color = \"blue\", alpha = 0.75) +\n  coord_equal() +\n  xlab(\"s1\") + ylab(\"s2\") + \n  scale_fill_gradient(low = \"yellow\", high = \"red\") +\n  scale_x_continuous(labels = comma) +\n  scale_y_continuous(labels = comma) +\n  theme_bw() +\n  labs(fill = \"Variance of predictions (gstat)\", size = \"Observed z\") +\n  theme(axis.text=element_text(size=12),\n        axis.title=element_text(size=14,face=\"bold\"))\n\n\ngrid.arrange(p3, p4, ncol = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-2.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n# Conclusion\n\nIn this first entry, I explore the foundational idea of Kriging interpolation, initially proposed by Danie G. Krige and later formalized mathematically by Georges Matheron [@matheron1963]. The prediction at a specific location, or interpolation over a spatial domain, can be done by solving a system of linear equations. The goal here is to demonstrate that Kriging can be applied both through its classical formulation and also by a \"Gaussian Process Regression\" (to be discussed in Part 2, coming sooon...).\n\n*Note: I am not an expert in using the `gstat` package, so the comparisons presented may not be optimal or the most efficient. The package was used solely for illustrative purposes.*\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}